{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d41261",
   "metadata": {},
   "source": [
    "Pretrain Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "564c66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%matplotlib inline\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from fnmatch import fnmatch\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Activation, Dense, Flatten,Conv1D, MaxPooling1D,Dropout,GlobalAveragePooling1D\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import concatenate\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "303f7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all .pkl files in a base directory. It will go to every sub directory find the .pkl file\n",
    "\n",
    "signals = [] # it will store all EDA signals of all subjects from \"chest\" device\n",
    "root = \"Dataset/WESAD/untitled folder/\"\n",
    "pattern = \"*.pkl\"\n",
    "signal_name='EDA'\n",
    "\n",
    "file_paths = glob.glob(root+pattern)\n",
    "subs=[]\n",
    "for path in  file_paths:\n",
    "    print(path)\n",
    "    with open(path, 'rb') as file:\n",
    "        data = pickle.load(file, encoding='latin1')\n",
    "    eda_signal= data['signal']['chest'][signal_name][:,0]\n",
    "    label=data['label']\n",
    "    numpy_data1=np.array([eda_signal,label])\n",
    "    numpy_data1=numpy_data1.T\n",
    "    df = pd.DataFrame(data=numpy_data1, columns=[signal_name,\"Label\"]) \n",
    "    df= df[df[\"Label\"]==1].reset_index(drop=True)\n",
    "    signals.append(df[signal_name].values)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9313133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects=[x.split('/')[-1].split('.')[0] for x in file_paths]\n",
    "import random\n",
    "def delete_random_elems(input_list, n):\n",
    "    to_delete = set(random.sample(range(len(input_list)), n))\n",
    "    return [x for i,x in enumerate(input_list) if not i in to_delete]\n",
    "\n",
    "\n",
    "signal_same_length = []\n",
    "\n",
    "for signal in signals:\n",
    "    if len(signal)==min([len(x) for x in signals]):\n",
    "        signal_same_length.append(signal)\n",
    "    else:\n",
    "        signal_same_length.append(np.array(delete_random_elems(signal, len(signal)-min([len(x) for x in signals]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4d5347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_with_forecasting(signal,window,output_length, overlap):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    start=0\n",
    "    while (True):\n",
    "        x1=signal[start:start+window]\n",
    "        output=signal[start+window:start+window+output_length] # 10 points\n",
    "        if (len(output)!=output_length):\n",
    "            break\n",
    "        X.append(x1)\n",
    "        y.append(output)\n",
    "        start=start+overlap\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53bbb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def viz(history,number,subject,signal_name,data_point):\n",
    "    plt.plot(history.history['mean_absolute_error'])\n",
    "    plt.plot(history.history['val_mean_absolute_error'])\n",
    "    plt.title('Mean Absolute Error')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(\"Results/Visualization/PretrainModelsWithForecastingAndRandomDatapoints/\"+signal_name+\"/\"+subject+\"/10Seconds_\"+str(number)+\"_\"+str(data_point)+\"_MAE.png\",dpi=500)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(\"Results/Visualization/PretrainModelsWithForecastingAndRandomDatapoints/\"+signal_name+\"/\"+subject+\"/10Seconds_\"+str(number)+\"_\"+str(data_point)+\"_Loss.png\",dpi=500)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "def evaluate_model_for_bar(trainX,trainy,testX,testy,window_size,output,number,subject,signal_name,data_point):\n",
    "    epoch=60\n",
    "#     trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    trainX,trainy,testX,testy = np.array(trainX), np.array(trainy), np.array(testX), np.array(testy)\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Conv1D(40, 4, activation='leaky_relu',padding=\"same\", input_shape=(trainX.shape[1],1)))\n",
    "\n",
    "    model.add(Conv1D(30, 2,padding=\"same\", activation='leaky_relu'))\n",
    "\n",
    "    model.add(Conv1D(18, 4,padding=\"same\", activation='leaky_relu'))\n",
    "\n",
    "    model.add(Conv1D(30, 2,padding=\"same\", activation='leaky_relu'))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(70, activation='leaky_relu'))\n",
    "    model.add(Dense(30, activation='leaky_relu'))\n",
    "    model.add(Dense(output, activation='linear'))\n",
    "    model.compile(loss=\"mean_squared_error\",optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "    model.fit(trainX, trainy, validation_split=0.1,epochs=epoch, batch_size=1000, verbose=0)\n",
    "    # evaluate model\n",
    "    _,rmse = model.evaluate(testX, testy,batch_size=1000, verbose=0)\n",
    "    rmse = math.sqrt(rmse)\n",
    "    \n",
    "    #save models\n",
    "    model.save(\"Models/PretrainModelsWithForecastingAndRandomDatapoints/\"+signal_name+\"/\"+subject+\"/RMSE_V2_10Seconds_\"+str(number)+\"_\"+str(data_point)+\"_model.h5\")\n",
    "\n",
    "    \n",
    "    df=pd.DataFrame({\n",
    "                    'Subject':[subject],\n",
    "                    'Data Point':[data_point],\n",
    "                    'Model No':[number],\n",
    "                     'Window Size': [window_size],\n",
    "                     'Output':[output],\n",
    "        \n",
    "                    'RMSE':[rmse],\n",
    "        \n",
    "                    'Signal':[signal_name]\n",
    "    })\n",
    "    print(rmse)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9327de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "data_points=[7000]\n",
    "\n",
    "signal='EDA'\n",
    "\n",
    "window_size=[7000]\n",
    "\n",
    "overlap=100\n",
    "subject_no=1\n",
    "for subject in subjects[subject_no-1:]:\n",
    "    evaluation_list=[]\n",
    "    z=1\n",
    "    for data_point in data_points:\n",
    "        for win in window_size:\n",
    "            for output_length in [40]:\n",
    "                print(subjects[subject_no-1],end=\",\")\n",
    "                print(data_point)\n",
    "                X,y=build_data_with_forecasting(signal_same_length[subject_no-1],win,output_length,overlap)\n",
    "                testX=X[910:]\n",
    "                testy=y[910:]\n",
    "                randomlist = random.sample(range(0, 7000), data_point) \n",
    "                trainX= [X[i] for i in randomlist] \n",
    "                trainy=[y[i] for i in randomlist]\n",
    "                eval_model= evaluate_model_for_bar(trainX,trainy,testX,testy,win,output_length,z,subject,signal,data_point)\n",
    "                z=z+1\n",
    "                evaluation_list.append(eval_model)\n",
    "    subject_no=subject_no+1\n",
    "    final_df= pd.concat(evaluation_list)\n",
    "    final_df.to_csv(r\"Models/PretrainModelsWithForecastingAndRandomDatapoints/\"+signal+\"/\"+subject+\"/RMSE_V2_10Seconds.csv\",index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be200fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "mastersthesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
