{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b4f1ba4",
   "metadata": {},
   "source": [
    "This notebook is for purely supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30f978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from fnmatch import fnmatch\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Activation, Dense, Flatten,Conv1D, MaxPooling1D,Dropout,GlobalAveragePooling1D\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import concatenate\n",
    "import glob\n",
    "import math\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a684995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all .pkl files in a base directory. It will go to every sub directory find the .pkl file\n",
    "\n",
    "signals = [] # it will store all EDA signals of all subjects from \"chest\" device\n",
    "root = \"Dataset/WESAD/untitled folder/\"\n",
    "pattern = \"*.pkl\"\n",
    "signal_name='EDA'\n",
    "\n",
    "file_paths = glob.glob(root+pattern)\n",
    "subs=[]\n",
    "for path in  file_paths:\n",
    "    print(path)\n",
    "    with open(path, 'rb') as file:\n",
    "        data = pickle.load(file, encoding='latin1')\n",
    "    eda_signal= data['signal']['chest'][signal_name][:,0]\n",
    "    label=data['label']\n",
    "    numpy_data1=np.array([eda_signal,label])\n",
    "    numpy_data1=numpy_data1.T\n",
    "    df = pd.DataFrame(data=numpy_data1, columns=[signal_name,\"Label\"]) \n",
    "    df= df[df[\"Label\"]==1].reset_index(drop=True)\n",
    "    signals.append(df[signal_name].values)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e997f4-7697-4410-bf0c-ce77c416c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects=[x.split('/')[-1].split('.')[0] for x in file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e58f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce048278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def delete_random_elems(input_list, n):\n",
    "    to_delete = set(random.sample(range(len(input_list)), n))\n",
    "    return [x for i,x in enumerate(input_list) if not i in to_delete]\n",
    "\n",
    "\n",
    "signal_same_length = []\n",
    "\n",
    "for signal in signals:\n",
    "    if len(signal)==min([len(x) for x in signals]):\n",
    "        signal_same_length.append(signal)\n",
    "    else:\n",
    "        signal_same_length.append(np.array(delete_random_elems(signal, len(signal)-min([len(x) for x in signals]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0c7eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subjects = ['S5', 'S2', 'S3', 'S4', 'S17', 'S10', 'S11', 'S16', 'S8',\n",
    "            'S6', 'S7', 'S9', 'S13', 'S14', 'S15']\n",
    "\n",
    "for question in range(0,6):\n",
    "    y=[]\n",
    "    i=0\n",
    "    for subject in subjects:\n",
    "        with open('/Users/ullash/MastersThesis/Dataset/QuestLabels/'+subject+'.pickle', 'rb') as handle:\n",
    "            b = pickle.load(handle)\n",
    "            y.append(b['values']['Base']['stai'][question])\n",
    "    y=pd.DataFrame(y)\n",
    "    y[0]= y[0].map({1:0.25,2:0.5,3:0.75,4:1})\n",
    "    y = list(y[0].values)\n",
    "    X=signal_same_length\n",
    "    \n",
    "    print(\"Question: \"+str(question))\n",
    "    for subject in subjects:\n",
    "        print(f'Subject ID: {subject}')\n",
    "        output = evaluate_model(subject,X,y,i,question)\n",
    "        evaluation_list.append(output)\n",
    "        i=i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b24f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_with_forecasting(signal,window,output_length, overlap):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    start=0\n",
    "    while (True):\n",
    "        x1=signal[start:start+window]\n",
    "        output=signal[start+window:start+window+output_length] # 10 points\n",
    "        if (len(output)!=output_length):\n",
    "            break\n",
    "        X.append(x1)\n",
    "        y.append(output)\n",
    "        start=start+overlap\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a7f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "def evaluate_model(trainX,trainy,testX,testy,subject,signal,question,data_point,step):\n",
    "    trainX,trainy,testX,testy=np.array(trainX),np.array(trainy),np.array(testX),np.array(testy)\n",
    "    \n",
    "    verbose, epochs, batch_size = 0, 100, 1000\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Conv1D(40, 4, activation='leaky_relu',padding=\"same\", input_shape=(trainX.shape[1],1)))\n",
    "    model.add(Conv1D(30, 2,padding=\"same\", activation='leaky_relu'))\n",
    "    model.add(Conv1D(18, 4,padding=\"same\", activation='leaky_relu'))\n",
    "    model.add(Conv1D(30, 2,padding=\"same\", activation='leaky_relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(70, activation='leaky_relu'))\n",
    "    model.add(Dense(30, activation='leaky_relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss=\"mean_squared_error\",optimizer='adam', metrics=[\"mean_squared_error\"])\n",
    "\n",
    "    \n",
    "    history=model.fit(np.array(trainX), np.array(trainy), validation_split=0.1,epochs=100, batch_size=2000, verbose=0)\n",
    "    _,mse = model.evaluate(np.array(testX), np.array(testy),batch_size=1000,verbose=0)\n",
    "    rmse = math.sqrt(abs(mse))\n",
    "    df=pd.DataFrame({'Subject':[subject],\n",
    "                     'Data point':[data_point],\n",
    "                     'Step':[step],\n",
    "                     'Question': [question],\n",
    "                     'SignAl':[signal],\n",
    "                    'RMSE':[rmse]})\n",
    "\n",
    "    print(\"RMSE\", str(rmse))\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d43075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "window=7000\n",
    "output_length = 40\n",
    "overlap = 100\n",
    "\n",
    "data_points=[10] \n",
    "signal=\"EDA\"\n",
    "# signal_same_length=signal_same_length[8:]\n",
    "# subjects = subjects[8:]\n",
    "subject_no = 1\n",
    "for subject  in subjects :\n",
    "    print(\"----------------------- ***** ------------------\")\n",
    "    print(\"Subject: -> \", str(subject_no))\n",
    "    for question in range(0,6):\n",
    "        evaluation_list=[]\n",
    "        y_new=[]\n",
    "        y=[]\n",
    "        with open('Dataset/QuestLabels/QuestLabels/'+subject+'.pickle', 'rb') as handle:\n",
    "            b = pickle.load(handle)\n",
    "            y.append(b['values']['Base']['stai'][question])\n",
    "        y=pd.DataFrame(y)\n",
    "        y[0]= y[0].map({1:0.25,2:0.5,3:0.75,4:1})\n",
    "        y = list(y[0].values) \n",
    "        for x in range(0,7910): # copy same output value as target to all  signals for. here total generated overlap signal 7910\n",
    "            y_new.append(y)\n",
    "        print(\"Subject: \",subject)\n",
    "        print(\"Question: \",question+1)\n",
    "        X_new= build_data_with_forecasting(signal_same_length[subject_no-1],window,output_length, overlap)\n",
    "        \n",
    "        X=X_new.copy()\n",
    "        y=y_new.copy()\n",
    "        testX=X[7000:]\n",
    "        testy=y[7000:]\n",
    "        for data_point in data_points:\n",
    "            for step in [1,2,3]:\n",
    "                print(\"Question: \", str(question), end=\",\")\n",
    "                print(\"Data Point: \", str(data_point), end=\",\")\n",
    "                print(\"step: \", str(step))\n",
    "                randomlist = random.sample(range(0, 7000), data_point) # Here 910 data points is for testing. thats why 7910-910=7000\n",
    "                trainX = [X[i] for i in randomlist] \n",
    "                trainy = [y[i] for i in randomlist]\n",
    "                eval_model = evaluate_model(trainX,trainy,testX,testy,subject,signal,question+1,data_point,step)\n",
    "                evaluation_list.append(eval_model)\n",
    "        df=pd.concat(evaluation_list)\n",
    "        df.to_csv(\"Models/ClassificationForecasting_withoutPretrain_AndRandomDatapoints/\"+signal+\"/\"+subject+\"/MAE_Question_\"+str(question)+\".csv\",index=False)\n",
    "        print(f\"df saved for {subject}, {question}\")\n",
    "    subject_no=subject_no+1\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "mastersthesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
