{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02f75d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%matplotlib inline\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from fnmatch import fnmatch\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Activation, Dense, Flatten,Conv1D, MaxPooling1D,Dropout,GlobalAveragePooling1D\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import concatenate\n",
    "import glob\n",
    "import math\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e78aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all .pkl files in a base directory. It will go to every sub directory find the .pkl file\n",
    "\n",
    "signals = [] # it will store all EDA signals of all subjects from \"chest\" device\n",
    "root = \"Dataset/WESAD/untitled folder/\"\n",
    "pattern = \"*.pkl\"\n",
    "signal_name='EDA'\n",
    "\n",
    "file_paths = glob.glob(root+pattern)\n",
    "subs=[]\n",
    "for path in  file_paths:\n",
    "    print(path)\n",
    "    with open(path, 'rb') as file:\n",
    "        data = pickle.load(file, encoding='latin1')\n",
    "    eda_signal= data['signal']['chest'][signal_name][:,0]\n",
    "    label=data['label']\n",
    "    numpy_data1=np.array([eda_signal,label])\n",
    "    numpy_data1=numpy_data1.T\n",
    "    df = pd.DataFrame(data=numpy_data1, columns=[signal_name,\"Label\"]) \n",
    "    df= df[df[\"Label\"]==1].reset_index(drop=True)\n",
    "    signals.append(df[signal_name].values)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abfc89a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects=[x.split('/')[-1].split('.')[0] for x in file_paths]\n",
    "subjects\n",
    "\n",
    "import random\n",
    "def delete_random_elems(input_list, n):\n",
    "    to_delete = set(random.sample(range(len(input_list)), n))\n",
    "    return [x for i,x in enumerate(input_list) if not i in to_delete]\n",
    "\n",
    "signal_same_length = []\n",
    "\n",
    "for signal in signals:\n",
    "    if len(signal)==min([len(x) for x in signals]):\n",
    "        signal_same_length.append(signal)\n",
    "    else:\n",
    "        signal_same_length.append(np.array(delete_random_elems(signal, len(signal)- min([len(x) for x in signals]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0aabe3-9f9f-4d04-a26f-5fda74096805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_model_selection(sub):\n",
    "    res=pd.read_csv(\"Models/PretrainModelsWithForecasting/\"+\"EDA/\"+sub+\"/30Seconds_\"+str(sub)+\"_mae.csv\")\n",
    "    res.sort_values(by=['MAE'],ascending=True, inplace=True)\n",
    "    model_no= res['Model No'].iloc[0]\n",
    "\n",
    "    import keras\n",
    "    model=keras.models.load_model(\"Models/PretrainModelsWithForecasting/\"+\"EDA\"+\"/\"+\"S\"+str(int(sub[1:]))+\"/30Seconds_\"+str(model_no)+\"_model.h5\")\n",
    "    inp = keras.layers.Input(shape=(798000,1), name='image_input')\n",
    "    for i in range(0,6):\n",
    "        model.layers[i].trainable = False\n",
    "\n",
    "    model.trainable = False\n",
    "    names=[]\n",
    "    for layer in model.layers:\n",
    "        names.append(layer.name)\n",
    "    getLayer=names[5]\n",
    "    last_layer = model.get_layer(getLayer).output\n",
    "    out = Dense(40, activation='leaky_relu')(last_layer)\n",
    "    out = Dense(30, activation='leaky_relu')(out)\n",
    "    out = Dense(10, activation='leaky_relu')(out)\n",
    "    out = Dense(1, activation='linear')(out)\n",
    "    new_model=Model(model.input, out)\n",
    "    return new_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b4ce7c5-bc28-4863-a713-0a272be81ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_data_with_forecasting(signal,window,output_length, overlap):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    start=0\n",
    "    while (True):\n",
    "        x1=signal[start:start+window]\n",
    "        output=signal[start+window:start+window+output_length] # 10 points\n",
    "        if (len(output)!=output_length):\n",
    "            break\n",
    "        X.append(x1)\n",
    "        y.append(output)\n",
    "        start=start+overlap\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf982c59-c135-46ed-b658-6cd80519bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX,trainy,testX,testy,subject,signal,question,data_point, model,step):\n",
    "    trainX,trainy,testX,testy=np.array(trainX),np.array(trainy),np.array(testX),np.array(testy)\n",
    "    \n",
    "    verbose, epochs, batch_size = 0, 100, 2000\n",
    "    \n",
    "    model.compile(loss=\"mean_squared_error\", optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "    \n",
    "    history=model.fit(np.array(trainX), np.array(trainy), validation_split=0.1,epochs=100, batch_size=2000, verbose=0)\n",
    "    _,mse = model.evaluate(np.array(testX), np.array(testy),batch_size=1000,verbose=0)\n",
    "    rmse = math.sqrt(abs(mse))\n",
    "\n",
    "    df=pd.DataFrame({'Subject':[subject],\n",
    "                     'Data point':[data_point],\n",
    "                     'Step':[step],\n",
    "                     'Question': [question],\n",
    "                     'SignAl':[signal],\n",
    "                    'RMSE':[rmse]})\n",
    "    print(rmse)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce7b14d-d0e2-4a04-bbf7-3f8a5664e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "window=7000\n",
    "output_length = 40\n",
    "overlap = 100\n",
    "\n",
    "data_points=[10,15, 20, 25,30, 40, 50, 60,80, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000,2000,3000,4000,6000,7000]  \n",
    "signal=\"EDA\"\n",
    "\n",
    "# signal_same_length=signal_same_length[7:]\n",
    "# subjects = ['S6']\n",
    "subject_no=1\n",
    "for subject  in subjects :\n",
    "    print(\"----------------------- ***** ------------------\")\n",
    "    print(\"Subject: -> \", str(subject_no))\n",
    "    for question in range(0,6):\n",
    "        evaluation_list=[]\n",
    "        y_new=[]\n",
    "        y=[]\n",
    "        with open('Dataset/QuestLabels/QuestLabels/'+subject+'.pickle', 'rb') as handle:\n",
    "            b = pickle.load(handle)\n",
    "            y.append(b['values']['Base']['stai'][question])\n",
    "        y=pd.DataFrame(y)\n",
    "        y[0]= y[0].map({1:0.25,2:0.5,3:0.75,4:1})\n",
    "        y = list(y[0].values) \n",
    "        for x in range(0,7910): # copy same output value as target to all  signals for. here total generated overlap signal 7910\n",
    "            y_new.append(y)\n",
    "    \n",
    "        X_new= build_data_with_forecasting(signal_same_length[subject_no-1],window,output_length, overlap)\n",
    "        \n",
    "        X=X_new.copy()\n",
    "        y=y_new.copy()\n",
    "        testX=X[7000:]\n",
    "        testy=y[7000:]\n",
    "        for data_point in data_points:\n",
    "            for step in [1,2,3]:\n",
    "                print(\"Question: \", str(question), end=\",\")\n",
    "                print(\"Data Point: \", str(data_point), end=\",\")\n",
    "                print(\"step: \", str(step))\n",
    "                randomlist = random.sample(range(0, 7000), data_point) # Here 910 data points is for testing. thats why 7910-910=7000\n",
    "                trainX= [X[i] for i in randomlist] \n",
    "                trainy=[y[i] for i in randomlist]\n",
    "                new_model = pretrain_model_selection(subject)\n",
    "                eval_model = evaluate_model(trainX,trainy,testX,testy,subject,signal,question+1,data_point,new_model,step)\n",
    "                evaluation_list.append(eval_model)\n",
    "        df=pd.concat(evaluation_list)       \n",
    "        df.to_csv(\"Models/ClassificationForecastingAndRandomDatapoints/\"+signal+\"/\"+subject+\"/RMSE_Question_\"+str(question)+\".csv\",index=False)\n",
    "        print(f\"df saved for S: {subject}, Q: {question}\")\n",
    "    subject_no=subject_no+1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea760d4-be2b-4938-b5c4-f82d583a9167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2867b-557e-4c7c-909b-808ba3b7dfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e2fee2-4634-40cf-bf3e-bb0315b820d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "mastersthesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
